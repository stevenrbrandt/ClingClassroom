{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPX + Cling + Jupyter\n",
    "\n",
    "## Docker Instructions\n",
    "* Frist, install docker and docker-compose on your local resource\n",
    "* Second, start Docker, e.g. ```sudo service docker start```\n",
    "* Third, run `curl -LO https://raw.githubusercontent.com/stevenrbrandt/CxxExplorer/master/docker-compose.yml`\n",
    "* Fourth, edit the docker-compose.yml and change the password to something other than `spoon`\n",
    "* Fifth, start the notebook by typing `docker-compose up -d`\n",
    "* Sixth, play with the existing ipynb files or create new ones.\n",
    "* Seven, save your work! This is an important step. If you simply quit the container, everything you did will be lost. You can copy individual files from the image to local disk as follows: `docker cp cxxex-src-nbk:/home/jovyan/HPX_by_example.ipynb ~/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <hpx/hpx.hpp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace std;\n",
    "using namespace hpx;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a (the) Future?\n",
    "\n",
    "Many ways to get hold of a future, simplest way is to use (std) async:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int universal_answer() { return 42; }\n",
    "void deep_thought()\n",
    "{\n",
    "  future<int> promised_answer = async(&universal_answer);\n",
    "  // do other things for 7.5 million years\n",
    "  cout << promised_answer.get() << endl; // prints 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_thought();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compositional Facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future<string> make_string()\n",
    "{\n",
    "    future<int> f1 = async([]()->int { return 123; });\n",
    "    future<string> f2 = f1.then(\n",
    "      [](future<int> f) -> string\n",
    "      {\n",
    "        return to_string(f.get()); // here .get() won't block\n",
    "      });\n",
    "    return f2;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cout << make_string().get() << endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template<typename W>\n",
    "int do_work(W& w) {\n",
    "  // extract the value of the first argument.\n",
    "  return hpx::get<0>(w.get()).get();\n",
    "}\n",
    "\n",
    "future<int> test_when_all()\n",
    "{\n",
    "  future<int> future1 = async([]()->int { return 125; });\n",
    "  future<string> future2 = async([]()->string { return string(\"hi\"); });\n",
    "  \n",
    "  auto all_f = when_all(future1,future2);\n",
    "  \n",
    "  future<int> result = all_f.then(\n",
    "    [](auto f)->int {\n",
    "      return do_work(f);\n",
    "    });\n",
    "  return result;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cout << test_when_all().get() << endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Algorithms\n",
    "HPX allows you to write loop parallel algorithms in a generic fashion, applying to specify the way in which parallelism is achieved (i.e. threads, distributed, cuda, etc.) through polcies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <hpx/include/parallel_for_each.hpp>\n",
    "#include <hpx/parallel/algorithms/transform.hpp>\n",
    "#include <boost/iterator/counting_iterator.hpp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector<int> v{ 1, 2, 3, 4, 5, 6 };"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "Here we demonstrate the transformation of a vector, and the various mechnanisms by which it can performed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// This parallel tranformation of vector v\n",
    "// is done using thread parallelism. An\n",
    "// implicit barrier is present at the end.\n",
    "hpx::transform (\n",
    "  hpx::execution::par,\n",
    "  begin(v), end(v), begin(v),\n",
    "  [](int i) -> int\n",
    "  {\n",
    "    return i+1;  \n",
    "  });\n",
    "for(int i : v) cout << i << \",\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// This parallel tranformation of vector v\n",
    "// is done using thread parallelism. There\n",
    "// is no implicit barrier. Instead, the\n",
    "// transform returns a future.\n",
    "auto  f = hpx::transform (\n",
    "  execution::par (execution::task),\n",
    "  begin(v), end(v), begin(v),\n",
    "  [](int i) -> int\n",
    "  {\n",
    "    return i+1;  \n",
    "  });\n",
    "  // work here...\n",
    "// wait for the future to be ready.\n",
    "f.wait();\n",
    "\n",
    "for(int i : v) cout << i << \",\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <hpx/include/parallel_fill.hpp>\n",
    "#include <hpx/include/compute.hpp>\n",
    "#include <hpx/include/parallel_executors.hpp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// targets are threads. Possibly, they each have their own locality (although by\n",
    "// using get_local_targets we'll only get targets on the current locality)\n",
    "auto host_targets = hpx::compute::host::get_local_targets();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// List the locality of all targets. These should all be the same.\n",
    "for(auto host : host_targets)\n",
    "  cout << hpx::get<0>(host.num_pus()) << endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <hpx/modules/compute.hpp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Get all targets on all localities and store in host_targets.\n",
    "// This notebook only uses a single locality, so this list should\n",
    "// be the same as the above.\n",
    "host_targets.clear();\n",
    "for (hpx::id_type const& locality : hpx::find_all_localities())\n",
    "{\n",
    "    std::vector<hpx::compute::host::distributed::target> targets =\n",
    "        hpx::compute::host::distributed::get_targets(locality).get();\n",
    "    host_targets.insert(end(host_targets),begin(targets),end(targets));\n",
    "}\n",
    "for(auto host : host_targets)\n",
    "  cout << hpx::get<0>(host.num_pus()) << endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Algorithms\n",
    "There are a great many algorithms. Here we demonstrate a handful of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typedef hpx::compute::host::block_executor<> executor_type;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Do a fill on the listed targets. We have supplied all of them,\n",
    "// though we don't need to. Note that the fill algorithm doesn't make sense\n",
    "// in a distributed setting since vector vd is not distributed.\n",
    "executor_type *exec = new executor_type(host_targets);\n",
    "std::vector<float> vd;\n",
    "for(int i=0;i<10;i++) vd.push_back(1.f);\n",
    "hpx::fill(execution::par.on(*exec),vd.begin(),vd.end(),1.0f*getpid());\n",
    "for(int i=0;i<10;i++) cout << vd[i] << \" \"; cout << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <hpx/parallel/algorithms/reverse.hpp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(int i=0;i<10;i++) vd.push_back(1.f*i);\n",
    "hpx::reverse(execution::par,vd.begin(),vd.end());\n",
    "for(int val : vd) cout << val << \" \";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <hpx/include/parallel_minmax.hpp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(int i=0;i<10;i++) vd.push_back(1.f*rand());\n",
    "auto ptr = hpx::max_element(execution::par,vd.begin(),vd.end(),std::less<float>());\n",
    "for(float val : vd) cout << val << \" \";\n",
    "cout << endl << *ptr << endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <hpx/execution.hpp>\n",
    "#include <hpx/include/parallel_executors.hpp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int count_async = 0;\n",
    "struct test_async_executor\n",
    "{\n",
    "    typedef hpx::execution::parallel_execution_tag execution_category;\n",
    "\n",
    "    template <typename F, typename ... Ts> \n",
    "    static hpx::future<typename result_of<F&&(Ts&&...)>::type>\n",
    "    async_execute(F && f, Ts &&... ts) \n",
    "    {   \n",
    "        ++count_async;\n",
    "        return hpx::async(hpx::launch::async, std::forward<F>(f),\n",
    "            std::forward<Ts>(ts)...);\n",
    "    }\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Note that the exact way to specify this trait for an executor is in flux\n",
    "// and the code here is tied to the specific version of HPX on the test machine.\n",
    "namespace hpx::parallel::execution\n",
    "{\n",
    "    template<>\n",
    "    struct is_two_way_executor<test_async_executor>\n",
    "      : std::true_type\n",
    "    {};\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <hpx/execution_base/execution.hpp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// This parallel tranformation of vector v\n",
    "// is done using using distributed parallelism.\n",
    "// NOTE: Ignore the warning\n",
    "test_async_executor e;\n",
    "hpx::transform (\n",
    "  execution::par.on(e),\n",
    "  begin(v), end(v), begin(v),\n",
    "  [](int i) -> int\n",
    "  {\n",
    "    return i+1;  \n",
    "  });\n",
    "cout << \"count=\" << count_async << endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let’s Parallelize It – Adding Real Asynchrony\n",
    "\n",
    "Here we take a step back. Instead of using a pre-designed parallel operation on a vector, we instead introduce task-level parallelism to an existing program.\n",
    "\n",
    "Calculate Fibonacci numbers in parallel (1st attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uint64_t fibonacci(uint64_t n)\n",
    "{\n",
    "  // if we know the answer, we return the value\n",
    "  if (n < 2) return n;\n",
    "  // asynchronously calculate one of the sub-terms\n",
    "  future<uint64_t> f = async(launch::async, &fibonacci, n-2);\n",
    "  // synchronously calculate the other sub-term\n",
    "  uint64_t r = fibonacci(n-1);\n",
    "  // wait for the future and calculate the result\n",
    "  return f.get() + r;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cout << fibonacci(10) << endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let’s Parallelize It – Introducing Control of Grain Size\n",
    "Parallel calculation, switching to serial execution below given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const int threshold = 20;\n",
    "\n",
    "uint64_t fibonacci_serial(uint64_t n)\n",
    "{\n",
    "  if (n < 2) return n;\n",
    "  uint64_t f1 = fibonacci_serial(n-2);\n",
    "  uint64_t f2 = fibonacci_serial(n-1);\n",
    "  return f1 + f2;\n",
    "}\n",
    "\n",
    "uint64_t fibonacci2(uint64_t n)\n",
    "{\n",
    "  if (n < 2) return n;\n",
    "  if (n < threshold) return fibonacci_serial(n);\n",
    "  // asynchronously calculate one of the sub-terms\n",
    "  future<uint64_t> f = async(launch::async, &fibonacci2, n-2);\n",
    "  // synchronously calculate the other sub-term\n",
    "  uint64_t r = fibonacci2(n-1);\n",
    "  // wait for the future and calculate the result\n",
    "  return f.get() + r;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cout << fibonacci2(22) << endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let’s Parallelize It – Apply Futurization\n",
    "Parallel way, futurize algorithm to remove suspension points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future<uint64_t> fibonacci3(uint64_t n)\n",
    "{\n",
    "  if(n < 2) return make_ready_future(n);\n",
    "  if(n < threshold) return make_ready_future(fibonacci_serial(n));\n",
    "\n",
    "  future<uint64_t> f = async(launch::async, &fibonacci3, n-2);\n",
    "  future<uint64_t> r = fibonacci3(n-1);\n",
    "\n",
    "  return dataflow(\n",
    "    [](future<uint64_t> f1, future<uint64_t> f2) {\n",
    "      return f1.get() + f2.get();\n",
    "    },\n",
    "    f, r);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cout << fibonacci3(22).get() << endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let’s Parallelize It – Unwrap Argument Futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using hpx::util::unwrapping;\n",
    "\n",
    "future<uint64_t> fibonacci4(uint64_t n)\n",
    "{\n",
    "  if(n < 2) return make_ready_future(n);\n",
    "  if(n < threshold) return make_ready_future(fibonacci_serial(n));\n",
    "\n",
    "  future<uint64_t> f = async(launch::async, &fibonacci4, n-2);\n",
    "  future<uint64_t> r = fibonacci4(n-1);\n",
    "\n",
    "  return dataflow(\n",
    "    hpx::unwrapping([](uint64_t f1, uint64_t f2)->uint64_t {\n",
    "      return f1+f2;\n",
    "    }),\n",
    "    f, r);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cout << fibonacci4(22).get() << endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Excercise: Parallelize a sort\n",
    "Test what you've learned. See if you can speed up the quicksort program below by find a place to:\n",
    "1. parallelize the code with async\n",
    "2. use parallel transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <unistd.h>\n",
    "#include <stdlib.h>\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "#include <functional>\n",
    "typedef std::vector<int>::iterator viter;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void myqsort(viter first, viter last) {\n",
    "  assert(first <= last);\n",
    "  ptrdiff_t range = last - first;\n",
    "  if(range > 1) {\n",
    "      auto pivot_value = first[rand() % range];\n",
    "      // Try converting this to use a parallel algorithm\n",
    "      auto middle1 = std::partition(first, last, [&](auto em) { return em < pivot_value;});\n",
    "      assert(middle1 <= last);\n",
    "      auto middle2 = std::partition(middle1, last, [&](auto em) { return em <= pivot_value;});\n",
    "      assert(middle2 <= last);\n",
    "\n",
    "      // try invoking this using hpx::async\n",
    "      myqsort(first,middle1);\n",
    "      myqsort(middle2,last);\n",
    "  }\n",
    "}\n",
    "vector<int> vv{20};\n",
    "for(int i=0;i<20;i++) vv.push_back(rand() % 100);\n",
    "for(int val : vv) cout << val << \" \";\n",
    "cout << endl;\n",
    "myqsort(begin(vv),end(vv));\n",
    "for(int val : vv) cout << val << \" \";\n",
    "cout << endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++",
   "name": "cling-cpp17"
  },
  "language_info": {
   "codemirror_mode": "c++",
   "file_extension": ".c++",
   "mimetype": "text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
